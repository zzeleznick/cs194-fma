---
layout: post
title: Images of the Russian Empire
subtitle: Colorizing the Prokudin-Gorskii Photo Collection
im2: "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg"
images: site.images
---

h2. {{ page.title }}

h3(anchor#main). %(octicon octicon-link)I. Background%

Sergei Mikhailovich Prokudin-Gorskii (1863-1944) [Сергей Михайлович Прокудин- Горский, to his Russian friends] was a man well ahead of his time. Convinced, as early as 1907, that color photography was the wave of the future, he won Tzar's special permission to travel across the vast Russian Empire and take color photographs of everything he saw including the only color portrait of Leo Tolstoy. And he really photographed everything: people, buildings, landscapes, railroads, bridges... thousands of color pictures! His idea was simple: record three exposures of every scene onto a glass plate using a red, a green, and a blue filter. Never mind that there was no way to print color photographs until much later -- he envisioned special projectors to be installed in "multimedia"classrooms all across Russia where the children would be able to learn about their vast country. Alas, his plans never materialized: he left Russia in 1918, right after the revolution, never to return again. Luckily, his RGB glass plate negatives, capturing the last years of the Russian Empire, survived and were purchased in 1948 by the Library of Congress. The LoC has recently digitized the negatives and made them available on-line.


h3(anchor#approach). %(octicon octicon-link)II. Approach%

I first started by testing the provided python skeleton code with a few input images in order to evaluate the baseline functionality of our naive colorize program. I noticed that naively assuming that the images were already nearly aligned (small displacement) and well balanced (centered on frame) proved to be a good starting point.

For alignment, the first function I implemented to test the "goodness of fit" was the sum of squared displacement (ssd). In python, this was extremely simple to code @sum(sum((image1-image2)**2))@ and I used ssd as my primary alignment function for the majority of the project. However, as I will note later, some images, like "emir.tif" required testing of multiple functions, feature inputs, and hyperparameters. Calculating the normalized dot product seemed to take slightly longer and did not produce as strong of results for my intial tests.

After running a few sample from the starter python skeleton code, I began to take note of the easiest improvements to implement. My first aim was to remove at least 60% of the white and black borders  — which I could do on a deterministic basis by trimming the the image matrices by a fixed percentage. Edge detection would come in later to remove the remaining junk pixels via a systematic approach. Secondly, I was really interested in exploring auto-contrast and white-balancing as low-hanging fruit. Thirdly, I wanted to experiment with edge detection as a better means for alignment and cropping.

h3(anchor#intermission). III. Early Results

{% comment %}
{% include halves-row.html im1="http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" im2 = "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" %}
{% assign im2 = "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" %}
{% assign im3 = "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" %}
{% endcomment %}


{% include thirds-row.html im1='http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg' im2 = 'http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg' im3 = 'http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg' %}
{% include thirds-row.html im1= page.im2 im2 = page.im2 im3 = page.im2 %}


{% comment %}
<!--div id="grid" class = "gg" data-columns>
    <div> !{{im2}}! </div>
    <div> !{{im2}}! </div>
    <div> !{{im3}}! </div>
        {% for image in site.images limit: 6 offset:0%}
            <div>
                <div> !{{ site.github_path | escape }}{{image.ref}}({{image.title}})!:{{image.link}} </div>
                <div>{{image.title}} {{image.data[0].size}}</div>
                <div>{{image.data[0].vector}}</div>
            </div>
        {% endfor %}
</div-->
{% endcomment %}

{% comment %}
<!--notextile>
<script type="text/javascript">
function callback(a){ return function(){ console.log("Running salvattore"); }}
var a = "world";
setTimeout(callback(a), 300);
a = "Stac Overflow";
salvattore.init();
</script>
</notextile-->
{% endcomment %}

{% capture size %} {{site.images | size }} {% endcapture %}



{% comment %}
{% include thirds-row.html im1="http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" im2 = "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" im3 = "http://inst.eecs.berkeley.edu/~cs194-26/fa15/hw/proj1/data/cathedral.jpg" %}
{% endcomment %}

|\2=. Output Images, Original Sizes, & Displacement Vectors[1] |
| !{{ site.github_path | escape }}images/output/out_cathedral.jpg(Cathedral)!:http://zzeleznick.github.io/cs194-fma/images/output/out_cathedral.jpg | !{{ site.github_path | escape  }}images/output/out_tobolsk.jpg(Tobolsk)!:http://zzeleznick.github.io/cs194-fma/images/output/out_tobolsk.jpg |
|=. Cathedral (1024, 390) |=. Tobolsk (1024, 396) |
|=. Green =  <2, -2>;  Red =   <6, -3> |=. Green =  <3, -4>;  Red =   <3, -7> |
| !{{ site.github_path | escape  }}images/output/out_nativity.jpg(Nativity)!:http://zzeleznick.github.io/cs194-fma/images/output/out_nativity.jpg | !{{ site.github_path | escape  }}images/output/out_settlers.jpg(Settlers)!:http://zzeleznick.github.io/cs194-fma/images/output/out_settlers.jpg |
|=. Nativity (1024, 395) |=. Settlers (1024, 396) |
|=. Green =  <1, -4>;  Red =   <0, -6> |=. Green = <0, 0>;  Red = <-1, 1>  |
| !{{ site.github_path | escape  }}images/output/out_monastery.jpg(Monastery)!:http://zzeleznick.github.io/cs194-fma/images/output/out_monastery.jpg | !{{ site.github_path | escape  }}images/output/de_out_monastery.jpg(White-Balanced Monastery)!:http://zzeleznick.github.io/cs194-fma/images/output/de_out_monastery.jpg |
|=. Monastery (1024, 391) |=. White-Balanced Monastery (1024, 391)[2] |
|=. Green = <2, -10>;  Red = <2, -11> |=. Green = <2, -10>;  Red = <2, -11>   |

h3(anchor#learnedlessons1). IV. Early Results Lessons Learned

After successfully running my program on the five smaller jpg files, I was pumped and completed my white-balance b&W and started to work on automatic cropping. I must admit that I was a little intimidated at first to create my own functions for edge detection, which was a crucial step for determining borders, since a watching a sharp change in pixels requires a lot of tuning to get right. I believe I spent more than 4 hours just tuning hyperparameters for cropping margins, adjusting cutoff values on the basis of deviation from the mean, median, and even some chained operations along specified rows. Hence, the need for edge detection.

h3(anchor#imagepyramid). V. Image Pyramid

The first images we tested were relatively small, with a max size of 405,504 pixels. I quickly realized that trying to use the same algorithm on one of the larger TIF files was extremely slow, and produced poor results due to the comparatively larger domain for alignment vectors. To resolve this issue, I created an image pyramid by scaling down the 3 channels by 2^i. Starting with the smallest image, the best alignment is found, and generated vector is used as the domain bounds for the next iteration. At each iteration, the image becomes closer to fullscale, but we are able to dramatically reduce the number of total steps we must traverse through the search space. Originally I used a pyramid height of 3, which mapped to {1/8, 1/4, 1/2, full} scale. However, for the emir image, I found that using a height of 2 helped prevent becoming stuck on a local minimum and produced a better result. Sadly, this reduced the quality of a few of the other images, and I was not able to adjust the hyperparameters of my evaluation function and search boundaries well enough for a single run through that I felt satisfied with. #todo.

|\2=. Output Images, Original Sizes, & Displacement Vectors[1] |
| !{{ site.github_path | escape  }}images/output/bridge.jpg(Bridge)!:http://zzeleznick.github.io/cs194-fma/images/output/bridge.jpg | !{{ site.github_path | escape  }}images/output/turkmen.jpg(Turkmen)!:http://zzeleznick.github.io/cs194-fma/images/output/turkmen.jpg |
|=. Bridge (9675, 3742) |=. Turkmen (9627, 3762) |
|=. Green =  <7, -33>;  Red =   <9, -38> |=. Green = <9, -12>;  Red = <19, -16> |
| !{{ site.github_path | escape  }}images/output/harvesters.jpg(Harvesters)!:http://zzeleznick.github.io/cs194-fma/images/output/harvesters.jpg | !{{ site.github_path | escape  }}images/output/icon.jpg(Icon)!:http://zzeleznick.github.io/cs194-fma/images/output/icon.jpg |
|=. Harvesters (9656, 3683) |=. Icon (9656, 3683) |
|=. Green =  <0, 8>;  Red =   <2, 5> |=. Green = <15, -17>;  Red = <17, -28>  |
| !{{ site.github_path | escape  }}images/output/lady.jpg(Lady)!:http://zzeleznick.github.io/cs194-fma/images/output/lady.jpg | !{{ site.github_path | escape  }}images/output/melons.jpg(Melons)!:http://zzeleznick.github.io/cs194-fma/images/output/melons.jpg |
|=. Monastery (9637, 3761) |=. Melons (9724, 3770) |
|=. Green = <0, -6>;  Red = <5, -10> |=. Green = <0, 13>;  Red = <8, 22>   |
| !{{ site.github_path | escape  }}images/output/onion_church.jpg(Onion Church)!:http://zzeleznick.github.io/cs194-fma/images/output/onion_church.jpg | !{{ site.github_path | escape  }}images/output/self_portrait.jpg(Self Portrait)!:http://zzeleznick.github.io/cs194-fma/images/output/self_portrait.jpg |
|=. Onion Church (9646, 3781) |=. Self Portrait (9754, 3810) |
|=. Green = <4, -13>;  Red = <9, -17> |=. Green = <8, 6>;  Red = <13, 9>   |
| !{{ site.github_path | escape  }}images/output/workshop.jpg(Workshop)!:http://zzeleznick.github.io/cs194-fma/images/output/workshop.jpg | !{{ site.github_path | escape  }}images/output/village.jpg(Village)!:http://zzeleznick.github.io/cs194-fma/images/output/village.jpg |
|=. Workshop (9627, 3741) |=. Village (9812, 3819) |
|=. Green = <0, -11>;  Red = <-14, -11> |=. Green = <13, -1>;  Red = <9, 6>   |
| !{{ site.github_path | escape  }}images/output/three_generations.jpg(Three Generations)!:http://zzeleznick.github.io/cs194-fma/images/output/three_generations.jpg | !{{ site.github_path | escape  }}images/output/train.jpg(Self Portrait)!:http://zzeleznick.github.io/cs194-fma/images/output/train.jpg |
|=. Three Generations (9629, 3714) |=. Train (9715, 3741) |
|=. Green = <-1, -3>;  Red = <10, -21> |=. Green = <-5, -18>;  Red = <24, -31>   |
| !{{ site.github_path | escape  }}images/output/emir.jpg(Emir)!:http://zzeleznick.github.io/cs194-fma/images/output/emir.jpg | !{{ site.github_path | escape  }}images/output/emir.jpg(Enhanced Emir)!:http://zzeleznick.github.io/cs194-fma/images/output/gamma_emir.jpg |
|=. Emir (9627, 3702) ) |=. Enhanced[3] Emir (9627, 3702) |
|=. Green =  <14, -17>;  Red =   <30, -18>  |=. Green =  <14, -17>;  Red =   <30, -18> |












fn1. Displacement Vectors are given as <dx, dy>, and were generated via comparing the ssd of the corresponding rolled image with baseline blue image.

fn2. I was quite excited to test out my white-balance algorithm -- so exicted in fact that I hadn't even finished my image pyramid implementation yet! This bell & whistle was achieved by finding the @max(sum(r,g,b values))@ along the centermost row and column, and then scaling all values by the appropriate transformation matrix. See "White Balance":https://en.wikipedia.org/wiki/White_balance for more.

fn3. Enhanced via an auto-contrast adjustment in which each pixel(x,y) was scaled by p(x,y)^1.5, and then normalized.



